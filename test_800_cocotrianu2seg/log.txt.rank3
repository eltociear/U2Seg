[12/25 17:52:25] detectron2 INFO: Rank of current process: 3. World size: 8
[12/25 17:52:27] detectron2 INFO: Environment info:
-------------------------------  -----------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.6 | packaged by conda-forge | (default, Jan 25 2021, 23:21:18) [GCC 9.3.0]
numpy                            1.24.4
detectron2                       0.6 @/shared/xinyang/u2seg_test/U2Seg-main/detectron2
Compiler                         GCC 11.2
CUDA compiler                    CUDA 12.2
detectron2 arch flags            7.5
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.1.2+cu121 @/home/xinyang/miniconda3/envs/u2seg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1,2,3,4,5,6,7              Quadro RTX 6000 (arch=7.5)
Driver version                   535.86.10
CUDA_HOME                        /usr/local/cuda
Pillow                           9.5.0
torchvision                      0.16.2+cu121 @/home/xinyang/miniconda3/envs/u2seg/lib/python3.8/site-packages/torchvision
torchvision arch flags           5.0, 6.0, 7.0, 7.5, 8.0, 8.6, 9.0
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.8.1
-------------------------------  -----------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[12/25 17:52:27] detectron2 INFO: Command line arguments: Namespace(config_file='./configs/COCO-PanopticSegmentation/u2seg_R50_800.yaml', dist_url='tcp://127.0.0.1:50195', eval_only=False, machine_rank=0, num_gpus=8, num_machines=1, opts=[], resume=False)
[12/25 17:52:27] detectron2 INFO: Contents of args.config_file=./configs/COCO-PanopticSegmentation/u2seg_R50_800.yaml:
_BASE_: "Base-Panoptic-FPN.yaml"
MODEL:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ]
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
#  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  WEIGHTS: "/home/niudt/detectron2/weights/dino_RN50_pretrain_d2_format.pkl" # please change this to the path where you save the pre-trained ckpt
  RESNETS:
    DEPTH: 50
    NORM: "SyncBN"
    STRIDE_IN_1X1: False
  BACKBONE:
    FREEZE_AT: 0
  SEM_SEG_HEAD:
    NUM_CLASSES: 28
  ROI_BOX_HEAD:
    CLS_AGNOSTIC_BBOX_REG: True
  RPN:
    POST_NMS_TOPK_TRAIN: 4000
    NMS_THRESH: 0.65
  FPN:
    NORM: "SyncBN"
  ROI_HEADS:
    NAME: CascadeROIHeads
    NUM_CLASSES: 800

SOLVER:
  STEPS: (210000, 250000)
  MAX_ITER: 270000
  IMS_PER_BATCH: 16
  BASE_LR: 0.01
  WEIGHT_DECAY: 0.00005
  GAMMA: 0.02
  CLIP_GRADIENTS:
    CLIP_TYPE: norm
    CLIP_VALUE: 1.0
    ENABLED: true
    NORM_TYPE: 2.0
  AMP:
    ENABLED: True
  CHECKPOINT_PERIOD: 10000


INPUT:
  MIN_SIZE_TRAIN: (240, 320, 480, 640, 672, 704, 736, 768, 800, 1024)
  MAX_SIZE_TRAIN: 1333
  MASK_FORMAT: "bitmask"
  FORMAT: "RGB"
TEST:
  EVAL_PERIOD: 0
  PRECISE_BN:
    ENABLED: True
    NUM_ITER: 200
  DETECTIONS_PER_IMAGE: 100

OUTPUT_DIR: ./test_800_cocotrianu2seg
[12/25 17:52:27] detectron2.utils.env INFO: Using a generated random seed 30742647
[12/25 17:52:28] detectron2.engine.defaults INFO: Model:
PanopticFPN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(
      256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output2): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral3): Conv2d(
      512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output3): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral4): Conv2d(
      1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output4): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_lateral5): Conv2d(
      2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fpn_output5): Conv2d(
      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
      (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): SyncBatchNorm(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): SyncBatchNorm(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): CascadeROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): ModuleList(
      (0-2): 3 x FastRCNNConvFCHead(
        (flatten): Flatten(start_dim=1, end_dim=-1)
        (fc1): Linear(in_features=12544, out_features=1024, bias=True)
        (fc_relu1): ReLU()
        (fc2): Linear(in_features=1024, out_features=1024, bias=True)
        (fc_relu2): ReLU()
      )
    )
    (box_predictor): ModuleList(
      (0-2): 3 x FastRCNNOutputLayers(
        (cls_score): Linear(in_features=1024, out_features=801, bias=True)
        (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)
      )
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 800, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (sem_seg_head): SemSegFPNHead(
    (p2): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode='bilinear')
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode='bilinear')
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode='bilinear')
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode='bilinear')
      (2): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode='bilinear')
      (4): Conv2d(
        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 128, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode='bilinear')
    )
    (predictor): Conv2d(128, 28, kernel_size=(1, 1), stride=(1, 1))
  )
)
[12/25 17:52:36] detectron2.data.datasets.coco INFO: Loading datasets/./prepare_ours/u2seg_annotations/ins_annotations/cocotrain_800.json takes 7.50 seconds.
[12/25 17:52:36] detectron2.data.datasets.coco INFO: Loaded 118239 images in COCO format from datasets/./prepare_ours/u2seg_annotations/ins_annotations/cocotrain_800.json
[12/25 17:52:43] detectron2.data.datasets.coco WARNING: Directory datasets/./coco/train2017 and datasets/./prepare_ours/u2seg_annotations/panoptic_annotations/panoptic_stuff_cocotrain_800 has 118287 and 118239 files, respectively.
[12/25 17:52:43] detectron2.data.datasets.coco WARNING: Will use their intersection of 118239 files.
[12/25 17:52:43] detectron2.data.datasets.coco INFO: Loaded 118239 images with semantic segmentation from datasets/./coco/train2017
[12/25 17:52:49] detectron2.data.build INFO: Distribution of instances among all 800 categories:
[36m|  category  | #instances   | category   | #instances   | category   | #instances   |
|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|
|     1      | 706          | 2          | 898          | 3          | 766          |
|     4      | 344          | 5          | 770          | 6          | 443          |
|     7      | 626          | 8          | 1112         | 9          | 801          |
|     10     | 675          | 11         | 504          | 12         | 723          |
|     13     | 780          | 14         | 956          | 15         | 509          |
|     16     | 465          | 17         | 440          | 18         | 520          |
|     19     | 582          | 20         | 861          | 21         | 607          |
|     22     | 714          | 23         | 590          | 24         | 882          |
|     25     | 688          | 26         | 698          | 27         | 540          |
|     28     | 663          | 29         | 827          | 30         | 487          |
|     31     | 708          | 32         | 533          | 33         | 0            |
|     34     | 1000         | 35         | 681          | 36         | 752          |
|     37     | 1007         | 38         | 437          | 39         | 503          |
|     40     | 814          | 41         | 614          | 42         | 661          |
|     43     | 613          | 44         | 771          | 45         | 402          |
|     46     | 614          | 47         | 658          | 48         | 681          |
|     49     | 693          | 50         | 854          | 51         | 558          |
|     52     | 458          | 53         | 1499         | 54         | 898          |
|     55     | 347          | 56         | 197          | 57         | 601          |
|     58     | 514          | 59         | 659          | 60         | 761          |
|     61     | 870          | 62         | 629          | 63         | 445          |
|     64     | 1179         | 65         | 779          | 66         | 0            |
|     67     | 528          | 68         | 947          | 69         | 1324         |
|     70     | 0            | 71         | 662          | 72         | 544          |
|     73     | 752          | 74         | 420          | 75         | 990          |
|     76     | 1077         | 77         | 562          | 78         | 486          |
|     79     | 399          | 80         | 414          | 81         | 739          |
|     82     | 883          | 83         | 1162         | 84         | 540          |
|     85     | 452          | 86         | 819          | 87         | 697          |
|     88     | 610          | 89         | 738          | 90         | 351          |
|     91     | 892          | 92         | 420          | 93         | 488          |
|     94     | 754          | 95         | 595          | 96         | 415          |
|     97     | 809          | 98         | 0            | 99         | 535          |
|    100     | 984          | 101        | 520          | 102        | 724          |
|    103     | 484          | 104        | 758          | 105        | 631          |
|    106     | 981          | 107        | 674          | 108        | 753          |
|    109     | 948          | 110        | 878          | 111        | 546          |
|    112     | 626          | 113        | 484          | 114        | 629          |
|    115     | 732          | 116        | 193          | 117        | 762          |
|    118     | 712          | 119        | 0            | 120        | 785          |
|    121     | 693          | 122        | 617          | 123        | 841          |
|    124     | 1125         | 125        | 505          | 126        | 431          |
|    127     | 544          | 128        | 730          | 129        | 948          |
|    130     | 1046         | 131        | 838          | 132        | 858          |
|    133     | 706          | 134        | 992          | 135        | 619          |
|    136     | 721          | 137        | 835          | 138        | 792          |
|    139     | 0            | 140        | 941          | 141        | 4            |
|    142     | 891          | 143        | 640          | 144        | 331          |
|    145     | 742          | 146        | 632          | 147        | 672          |
|    148     | 676          | 149        | 566          | 150        | 414          |
|    151     | 922          | 152        | 540          | 153        | 674          |
|    154     | 534          | 155        | 580          | 156        | 725          |
|    157     | 695          | 158        | 278          | 159        | 0            |
|    160     | 838          | 161        | 0            | 162        | 1254         |
|    163     | 678          | 164        | 625          | 165        | 223          |
|    166     | 1109         | 167        | 632          | 168        | 351          |
|    169     | 0            | 170        | 1022         | 171        | 987          |
|    172     | 940          | 173        | 198          | 174        | 923          |
|    175     | 788          | 176        | 527          | 177        | 618          |
|    178     | 520          | 179        | 572          | 180        | 594          |
|    181     | 630          | 182        | 963          | 183        | 598          |
|    184     | 691          | 185        | 677          | 186        | 569          |
|    187     | 653          | 188        | 1151         | 189        | 1232         |
|    190     | 721          | 191        | 1105         | 192        | 758          |
|    193     | 542          | 194        | 544          | 195        | 786          |
|    196     | 888          | 197        | 418          | 198        | 620          |
|    199     | 307          | 200        | 657          | 201        | 770          |
|    202     | 742          | 203        | 362          | 204        | 607          |
|    205     | 0            | 206        | 586          | 207        | 516          |
|    208     | 435          | 209        | 489          | 210        | 951          |
|    211     | 541          | 212        | 758          | 213        | 462          |
|    214     | 679          | 215        | 273          | 216        | 709          |
|    217     | 1041         | 218        | 958          | 219        | 561          |
|    220     | 949          | 221        | 0            | 222        | 545          |
|    223     | 702          | 224        | 852          | 225        | 612          |
|    226     | 990          | 227        | 929          | 228        | 867          |
|    229     | 553          | 230        | 700          | 231        | 600          |
|    232     | 973          | 233        | 555          | 234        | 732          |
|    235     | 344          | 236        | 379          | 237        | 1005         |
|    238     | 422          | 239        | 415          | 240        | 655          |
|    241     | 718          | 242        | 547          | 243        | 585          |
|    244     | 623          | 245        | 950          | 246        | 605          |
|    247     | 873          | 248        | 1027         | 249        | 549          |
|    250     | 788          | 251        | 519          | 252        | 760          |
|    253     | 579          | 254        | 846          | 255        | 616          |
|    256     | 649          | 257        | 736          | 258        | 883          |
|    259     | 900          | 260        | 539          | 261        | 411          |
|    262     | 735          | 263        | 0            | 264        | 672          |
|    265     | 0            | 266        | 1009         | 267        | 826          |
|    268     | 1079         | 269        | 325          | 270        | 353          |
|    271     | 648          | 272        | 764          | 273        | 673          |
|    274     | 609          | 275        | 774          | 276        | 0            |
|    277     | 693          | 278        | 472          | 279        | 585          |
|    280     | 440          | 281        | 525          | 282        | 590          |
|    283     | 700          | 284        | 749          | 285        | 722          |
|    286     | 500          | 287        | 422          | 288        | 567          |
|    289     | 814          | 290        | 0            | 291        | 780          |
|    292     | 452          | 293        | 591          | 294        | 0            |
|    295     | 696          | 296        | 570          | 297        | 485          |
|    298     | 505          | 299        | 321          | 300        | 584          |
|    301     | 0            | 302        | 1188         | 303        | 444          |
|    304     | 0            | 305        | 688          | 306        | 670          |
|    307     | 1114         | 308        | 648          | 309        | 0            |
|    310     | 574          | 311        | 692          | 312        | 625          |
|    313     | 531          | 314        | 516          | 315        | 704          |
|    316     | 601          | 317        | 818          | 318        | 539          |
|    319     | 517          | 320        | 339          | 321        | 431          |
|    322     | 685          | 323        | 849          | 324        | 548          |
|    325     | 657          | 326        | 585          | 327        | 818          |
|    328     | 0            | 329        | 406          | 330        | 462          |
|    331     | 706          | 332        | 1164         | 333        | 450          |
|    334     | 0            | 335        | 580          | 336        | 592          |
|    337     | 1133         | 338        | 549          | 339        | 766          |
|    340     | 445          | 341        | 681          | 342        | 704          |
|    343     | 639          | 344        | 770          | 345        | 779          |
|    346     | 0            | 347        | 1120         | 348        | 1353         |
|    349     | 564          | 350        | 388          | 351        | 959          |
|    352     | 854          | 353        | 1101         | 354        | 720          |
|    355     | 343          | 356        | 360          | 357        | 533          |
|    358     | 625          | 359        | 531          | 360        | 409          |
|    361     | 743          | 362        | 568          | 363        | 683          |
|    364     | 581          | 365        | 0            | 366        | 0            |
|    367     | 1033         | 368        | 602          | 369        | 0            |
|    370     | 0            | 371        | 358          | 372        | 471          |
|    373     | 670          | 374        | 0            | 375        | 515          |
|    376     | 1072         | 377        | 617          | 378        | 1020         |
|    379     | 823          | 380        | 556          | 381        | 0            |
|    382     | 736          | 383        | 1014         | 384        | 661          |
|    385     | 497          | 386        | 741          | 387        | 927          |
|    388     | 1034         | 389        | 1029         | 390        | 228          |
|    391     | 0            | 392        | 457          | 393        | 0            |
|    394     | 709          | 395        | 644          | 396        | 426          |
|    397     | 545          | 398        | 665          | 399        | 917          |
|    400     | 576          | 401        | 980          | 402        | 619          |
|    403     | 764          | 404        | 351          | 405        | 947          |
|    406     | 1202         | 407        | 642          | 408        | 0            |
|    409     | 664          | 410        | 628          | 411        | 572          |
|    412     | 1326         | 413        | 560          | 414        | 758          |
|    415     | 513          | 416        | 427          | 417        | 768          |
|    418     | 120          | 419        | 576          | 420        | 612          |
|    421     | 393          | 422        | 454          | 423        | 625          |
|    424     | 0            | 425        | 725          | 426        | 628          |
|    427     | 707          | 428        | 0            | 429        | 851          |
|    430     | 732          | 431        | 658          | 432        | 422          |
|    433     | 579          | 434        | 609          | 435        | 750          |
|    436     | 794          | 437        | 592          | 438        | 1177         |
|    439     | 697          | 440        | 900          | 441        | 832          |
|    442     | 994          | 443        | 858          | 444        | 725          |
|    445     | 835          | 446        | 335          | 447        | 539          |
|    448     | 378          | 449        | 727          | 450        | 815          |
|    451     | 750          | 452        | 794          | 453        | 640          |
|    454     | 555          | 455        | 661          | 456        | 1172         |
|    457     | 659          | 458        | 829          | 459        | 659          |
|    460     | 0            | 461        | 523          | 462        | 811          |
|    463     | 520          | 464        | 597          | 465        | 740          |
|    466     | 0            | 467        | 0            | 468        | 444          |
|    469     | 1378         | 470        | 480          | 471        | 638          |
|    472     | 953          | 473        | 522          | 474        | 755          |
|    475     | 707          | 476        | 703          | 477        | 696          |
|    478     | 0            | 479        | 444          | 480        | 1845         |
|    481     | 568          | 482        | 1362         | 483        | 1547         |
|    484     | 724          | 485        | 711          | 486        | 849          |
|    487     | 835          | 488        | 921          | 489        | 1092         |
|    490     | 704          | 491        | 678          | 492        | 803          |
|    493     | 653          | 494        | 516          | 495        | 520          |
|    496     | 264          | 497        | 620          | 498        | 498          |
|    499     | 682          | 500        | 502          | 501        | 376          |
|    502     | 405          | 503        | 1412         | 504        | 846          |
|    505     | 551          | 506        | 926          | 507        | 733          |
|    508     | 502          | 509        | 343          | 510        | 1610         |
|    511     | 733          | 512        | 371          | 513        | 451          |
|    514     | 719          | 515        | 617          | 516        | 605          |
|    517     | 540          | 518        | 720          | 519        | 571          |
|    520     | 659          | 521        | 1021         | 522        | 876          |
|    523     | 619          | 524        | 978          | 525        | 645          |
|    526     | 472          | 527        | 285          | 528        | 819          |
|    529     | 381          | 530        | 322          | 531        | 521          |
|    532     | 747          | 533        | 400          | 534        | 491          |
|    535     | 854          | 536        | 840          | 537        | 773          |
|    538     | 508          | 539        | 422          | 540        | 744          |
|    541     | 591          | 542        | 656          | 543        | 614          |
|    544     | 668          | 545        | 429          | 546        | 855          |
|    547     | 771          | 548        | 1963         | 549        | 524          |
|    550     | 0            | 551        | 455          | 552        | 973          |
|    553     | 392          | 554        | 669          | 555        | 329          |
|    556     | 575          | 557        | 499          | 558        | 521          |
|    559     | 0            | 560        | 891          | 561        | 640          |
|    562     | 604          | 563        | 649          | 564        | 725          |
|    565     | 817          | 566        | 486          | 567        | 489          |
|    568     | 656          | 569        | 396          | 570        | 656          |
|    571     | 605          | 572        | 1146         | 573        | 586          |
|    574     | 536          | 575        | 954          | 576        | 489          |
|    577     | 834          | 578        | 553          | 579        | 612          |
|    580     | 823          | 581        | 804          | 582        | 533          |
|    583     | 811          | 584        | 569          | 585        | 554          |
|    586     | 439          | 587        | 591          | 588        | 584          |
|    589     | 986          | 590        | 1123         | 591        | 540          |
|    592     | 856          | 593        | 605          | 594        | 747          |
|    595     | 994          | 596        | 517          | 597        | 619          |
|    598     | 315          | 599        | 750          | 600        | 1001         |
|    601     | 0            | 602        | 639          | 603        | 435          |
|    604     | 947          | 605        | 1081         | 606        | 373          |
|    607     | 534          | 608        | 410          | 609        | 687          |
|    610     | 503          | 611        | 544          | 612        | 0            |
|    613     | 421          | 614        | 457          | 615        | 0            |
|    616     | 0            | 617        | 614          | 618        | 802          |
|    619     | 731          | 620        | 560          | 621        | 919          |
|    622     | 0            | 623        | 560          | 624        | 908          |
|    625     | 860          | 626        | 359          | 627        | 730          |
|    628     | 854          | 629        | 0            | 630        | 1001         |
|    631     | 744          | 632        | 638          | 633        | 528          |
|    634     | 279          | 635        | 872          | 636        | 710          |
|    637     | 821          | 638        | 990          | 639        | 633          |
|    640     | 688          | 641        | 1202         | 642        | 420          |
|    643     | 1204         | 644        | 777          | 645        | 873          |
|    646     | 595          | 647        | 442          | 648        | 1067         |
|    649     | 655          | 650        | 527          | 651        | 371          |
|    652     | 611          | 653        | 869          | 654        | 893          |
|    655     | 330          | 656        | 470          | 657        | 450          |
|    658     | 0            | 659        | 556          | 660        | 625          |
|    661     | 977          | 662        | 561          | 663        | 760          |
|    664     | 36666        | 665        | 377          | 666        | 471          |
|    667     | 420          | 668        | 754          | 669        | 712          |
|    670     | 815          | 671        | 355          | 672        | 249          |
|    673     | 502          | 674        | 0            | 675        | 433          |
|    676     | 915          | 677        | 487          | 678        | 908          |
|    679     | 544          | 680        | 427          | 681        | 647          |
|    682     | 494          | 683        | 435          | 684        | 536          |
|    685     | 675          | 686        | 339          | 687        | 628          |
|    688     | 467          | 689        | 719          | 690        | 732          |
|    691     | 623          | 692        | 818          | 693        | 680          |
|    694     | 731          | 695        | 943          | 696        | 1015         |
|    697     | 546          | 698        | 598          | 699        | 889          |
|    700     | 793          | 701        | 854          | 702        | 587          |
|    703     | 253          | 704        | 550          | 705        | 694          |
|    706     | 554          | 707        | 1080         | 708        | 0            |
|    709     | 674          | 710        | 410          | 711        | 655          |
|    712     | 0            | 713        | 637          | 714        | 531          |
|    715     | 895          | 716        | 987          | 717        | 678          |
|    718     | 364          | 719        | 351          | 720        | 532          |
|    721     | 592          | 722        | 0            | 723        | 668          |
|    724     | 594          | 725        | 899          | 726        | 1262         |
|    727     | 595          | 728        | 595          | 729        | 679          |
|    730     | 741          | 731        | 667          | 732        | 655          |
|    733     | 501          | 734        | 733          | 735        | 746          |
|    736     | 1170         | 737        | 567          | 738        | 1194         |
|    739     | 363          | 740        | 943          | 741        | 333          |
|    742     | 0            | 743        | 520          | 744        | 737          |
|    745     | 0            | 746        | 613          | 747        | 281          |
|    748     | 715          | 749        | 791          | 750        | 553          |
|    751     | 0            | 752        | 546          | 753        | 0            |
|    754     | 811          | 755        | 1152         | 756        | 731          |
|    757     | 867          | 758        | 498          | 759        | 520          |
|    760     | 438          | 761        | 0            | 762        | 757          |
|    763     | 1002         | 764        | 772          | 765        | 0            |
|    766     | 714          | 767        | 760          | 768        | 491          |
|    769     | 312          | 770        | 669          | 771        | 614          |
|    772     | 719          | 773        | 1213         | 774        | 638          |
|    775     | 0            | 776        | 389          | 777        | 809          |
|    778     | 534          | 779        | 463          | 780        | 483          |
|    781     | 0            | 782        | 524          | 783        | 646          |
|    784     | 818          | 785        | 657          | 786        | 1067         |
|    787     | 568          | 788        | 617          | 789        | 797          |
|    790     | 463          | 791        | 875          | 792        | 943          |
|    793     | 309          | 794        | 439          | 795        | 1051         |
|    796     | 592          | 797        | 461          | 798        | 923          |
|    799     | 744          | 800        | 519          |            |              |
|   total    | 540498       |            |              |            |              |[0m
[12/25 17:52:49] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(240, 320, 480, 640, 672, 704, 736, 768, 800, 1024), max_size=1333, sample_style='choice'), RandomFlip()]
[12/25 17:52:49] detectron2.data.build INFO: Using training sampler TrainingSampler
[12/25 17:52:51] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/25 17:52:51] detectron2.data.common INFO: Serializing 118239 elements to byte tensors and concatenating them all ...
[12/25 17:52:53] detectron2.data.common INFO: Serialized dataset takes 416.17 MiB
[12/25 17:52:53] detectron2.data.build INFO: Making batched data loader with batch_size=2
[12/25 17:53:01] detectron2.data.datasets.coco INFO: Loading datasets/./prepare_ours/u2seg_annotations/ins_annotations/cocotrain_800.json takes 6.91 seconds.
[12/25 17:53:01] detectron2.data.datasets.coco INFO: Loaded 118239 images in COCO format from datasets/./prepare_ours/u2seg_annotations/ins_annotations/cocotrain_800.json
[12/25 17:53:08] detectron2.data.datasets.coco WARNING: Directory datasets/./coco/train2017 and datasets/./prepare_ours/u2seg_annotations/panoptic_annotations/panoptic_stuff_cocotrain_800 has 118287 and 118239 files, respectively.
[12/25 17:53:08] detectron2.data.datasets.coco WARNING: Will use their intersection of 118239 files.
[12/25 17:53:09] detectron2.data.datasets.coco INFO: Loaded 118239 images with semantic segmentation from datasets/./coco/train2017
[12/25 17:53:14] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(240, 320, 480, 640, 672, 704, 736, 768, 800, 1024), max_size=1333, sample_style='choice'), RandomFlip()]
[12/25 17:53:14] detectron2.data.build INFO: Using training sampler TrainingSampler
[12/25 17:53:15] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[12/25 17:53:15] detectron2.data.common INFO: Serializing 118239 elements to byte tensors and concatenating them all ...
[12/25 17:53:16] detectron2.data.common INFO: Serialized dataset takes 416.17 MiB
[12/25 17:53:16] detectron2.data.build INFO: Making batched data loader with batch_size=2
[12/25 17:53:17] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /home/niudt/detectron2/weights/dino_RN50_pretrain_d2_format.pkl ...
[12/25 17:53:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/niudt/detectron2/weights/dino_RN50_pretrain_d2_format.pkl ...
[12/25 17:53:17] fvcore.common.checkpoint INFO: Reading a file from 'MoCo'
[12/25 17:53:17] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up - Total num: 53
[12/25 17:53:17] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_lateral2.weight[0m
[34mbackbone.fpn_lateral3.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_lateral3.weight[0m
[34mbackbone.fpn_lateral4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_lateral4.weight[0m
[34mbackbone.fpn_lateral5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_lateral5.weight[0m
[34mbackbone.fpn_output2.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_output2.weight[0m
[34mbackbone.fpn_output3.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_output3.weight[0m
[34mbackbone.fpn_output4.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_output4.weight[0m
[34mbackbone.fpn_output5.norm.{bias, running_mean, running_var, weight}[0m
[34mbackbone.fpn_output5.weight[0m
[34mproposal_generator.rpn_head.anchor_deltas.{bias, weight}[0m
[34mproposal_generator.rpn_head.conv.{bias, weight}[0m
[34mproposal_generator.rpn_head.objectness_logits.{bias, weight}[0m
[34mroi_heads.box_head.0.fc1.{bias, weight}[0m
[34mroi_heads.box_head.0.fc2.{bias, weight}[0m
[34mroi_heads.box_head.1.fc1.{bias, weight}[0m
[34mroi_heads.box_head.1.fc2.{bias, weight}[0m
[34mroi_heads.box_head.2.fc1.{bias, weight}[0m
[34mroi_heads.box_head.2.fc2.{bias, weight}[0m
[34mroi_heads.box_predictor.0.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.0.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.1.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.1.cls_score.{bias, weight}[0m
[34mroi_heads.box_predictor.2.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.2.cls_score.{bias, weight}[0m
[34mroi_heads.mask_head.deconv.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn1.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn2.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn3.{bias, weight}[0m
[34mroi_heads.mask_head.mask_fcn4.{bias, weight}[0m
[34mroi_heads.mask_head.predictor.{bias, weight}[0m
[34msem_seg_head.p2.0.norm.{bias, weight}[0m
[34msem_seg_head.p2.0.weight[0m
[34msem_seg_head.p3.0.norm.{bias, weight}[0m
[34msem_seg_head.p3.0.weight[0m
[34msem_seg_head.p4.0.norm.{bias, weight}[0m
[34msem_seg_head.p4.0.weight[0m
[34msem_seg_head.p4.2.norm.{bias, weight}[0m
[34msem_seg_head.p4.2.weight[0m
[34msem_seg_head.p5.0.norm.{bias, weight}[0m
[34msem_seg_head.p5.0.weight[0m
[34msem_seg_head.p5.2.norm.{bias, weight}[0m
[34msem_seg_head.p5.2.weight[0m
[34msem_seg_head.p5.4.norm.{bias, weight}[0m
[34msem_seg_head.p5.4.weight[0m
[34msem_seg_head.predictor.{bias, weight}[0m
[12/25 17:53:17] detectron2.engine.train_loop INFO: Starting training from iteration 0
[12/25 17:55:41] detectron2.engine.hooks INFO: Overall training speed: 99 iterations in 0:01:54 (1.1534 s / it)
[12/25 17:55:41] detectron2.engine.hooks INFO: Total training time: 0:01:54 (0:00:00 on hooks)
